{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T03:53:31.940766Z",
     "start_time": "2019-07-07T03:53:31.935868Z"
    }
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T21:29:45.261446Z",
     "start_time": "2021-11-17T21:29:45.239505Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, re, sys, pickle, datetime\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA,NMF\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectKBest,f_regression,mutual_info_regression\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LogisticRegression,Lasso,LinearRegression,Ridge,ElasticNetCV,ElasticNet,Lars,LassoCV,RidgeCV,LarsCV,LassoLarsCV,LassoLarsIC,OrthogonalMatchingPursuitCV,OrthogonalMatchingPursuit\n",
    "from sklearn.manifold import TSNE,MDS\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV,RepeatedKFold,LeaveOneOut,cross_val_score,cross_validate\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier,MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC,SVR\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "#from sklearn import tree\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import multiprocessing\n",
    "nproc = max([1,multiprocessing.cpu_count()-2])\n",
    "from joblib import Parallel,delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import loo_q2 as loo\n",
    "\n",
    "randomstate = 42\n",
    "\n",
    "def plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"y\",loo_pred=[]):\n",
    "    y_orig_min = np.min(np.hstack((y_train,y_test)))\n",
    "    y_pred_min = np.min(np.hstack((y_pred_train,y_pred_test)))\n",
    "    y_orig_max = np.max(np.hstack((y_train,y_test)))\n",
    "    y_pred_max = np.max(np.hstack((y_pred_train,y_pred_test)))\n",
    "    delta_x = 0.04 * (y_orig_max-y_orig_min)\n",
    "    delta_y = 0.04 * (y_pred_max-y_pred_min)\n",
    "           \n",
    "    yy_fit = np.polyfit(y_train,y_pred_train,deg=1)\n",
    "    yy_fit_line = yy_fit[1]+yy_fit[0]*y_train\n",
    "    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    # plt.plot(np.linspace(y_orig_min-delta_x,y_orig_max+delta_x), np.linspace(y_orig_min-delta_x,y_orig_max+delta_x),color=\"grey\")\n",
    "    plt.xlim([y_orig_min-delta_x,y_orig_max+delta_x])\n",
    "    plt.ylim([y_pred_min-delta_y,y_pred_max+delta_y])\n",
    "    if len(loo_pred) != 0:\n",
    "        plt.scatter(y_train,loo_train,label=\"LOO\",color=\"black\",marker=\".\",facecolor='none',s=200)\n",
    "    plt.scatter(y_train,y_pred_train,label=\"training\",color=\"black\",marker=\".\",s=200) # ,alpha=0.6\n",
    "    plt.scatter(y_test,y_pred_test,label=\"test\",color='red',marker=\".\",linewidth=3, s=200)     #,alpha=0.25  \"#8da9f5\"\n",
    "    plt.plot(y_train,yy_fit_line,color=\"darkgrey\",linestyle='--',dashes=[5,15]) #,alpha=0.2\n",
    "    if leg:\n",
    "        plt.legend(loc='lower right', fontsize=10)\n",
    "    plt.xlabel(label+\" measured\",fontsize=18, fontweight='bold')\n",
    "    plt.ylabel(label+\" predicted\",fontsize=18, fontweight='bold')\n",
    "    \n",
    "    plt.xticks(fontsize=18)\n",
    "    plt.yticks(fontsize=18)\n",
    "    \n",
    "    plt.gca().spines['right'].set_color('none')\n",
    "    plt.gca().spines['top'].set_color('none')\n",
    "    \n",
    "    if not sav:\n",
    "        plt.show()  \n",
    "    else:\n",
    "        plt.savefig(sav, dpi=300, bbox_inches='tight', transparent=True)\n",
    "        \n",
    "def r2_val(y_test,y_pred_test,y_train):\n",
    "    \"\"\"Calculates the external R2 pred as described:\n",
    "    https://pdfs.semanticscholar.org/4eb2/5ff5a87f2fd6789c5b9954eddddfd1c59dab.pdf\"\"\"\n",
    "    y_resid = y_pred_test - y_test\n",
    "    SS_resid = np.sum(y_resid**2)\n",
    "    y_var = y_test - np.mean(y_train)\n",
    "    SS_total = np.sum(y_var**2)\n",
    "    r2_validation = 1-SS_resid/SS_total\n",
    "    return(r2_validation)\n",
    "\n",
    "def repeated_k_fold(X_train,y_train,reg = LinearRegression(), k=3, n=100):\n",
    "    \"\"\"Reapeated k-fold cross-validation. \n",
    "    For each of n repeats, the (training)data is split into k folds. \n",
    "    For each fold, this part of the data is predicted using the rest. \n",
    "    Once this is done for all k folds, the coefficient of determination (R^2) of the predictions of all folds combined (= the complete data set) is evaluated\n",
    "    This is repeated n times and all n R^2 are returned for averaging/further analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    rkf = RepeatedKFold(n_splits=k, n_repeats=n)\n",
    "    r2_scores = []\n",
    "    y_validations,y_predictions = np.zeros((np.shape(X_train)[0],n)),np.zeros((np.shape(X_train)[0],n))\n",
    "    foldcount = 0\n",
    "    for i,foldsplit in enumerate(rkf.split(X_train)):\n",
    "        fold, rep = i%k, int(i/k) # Which of k folds. Which of n repeats\n",
    "        model = reg.fit(X_train[foldsplit[0]],y_train[foldsplit[0]]) # foldsplit[0]: k-1 training folds\n",
    "        y_validations[foldcount:foldcount+len(foldsplit[1]),rep] = y_train[foldsplit[1]] # foldsplit[1]: validation fold\n",
    "        y_predictions[foldcount:foldcount+len(foldsplit[1]),rep]  = model.predict(X_train[foldsplit[1]])\n",
    "        foldcount += len(foldsplit[1])\n",
    "        if fold+1==k:\n",
    "            foldcount = 0\n",
    "    r2_scores = np.asarray([metrics.r2_score(y_validations[:,rep],y_predictions[:,rep]) for rep in range(n)])\n",
    "    return(r2_scores)\n",
    "\n",
    "# keepmodels = []\n",
    "\n",
    "import random\n",
    "insu = [\"yikes. that's ass.\",\"LMAO do not publish this what are you doing\",\"oof.\",\"that's a rough one\",\"I'm embarassed to even print this, but here it is:\",\"more disappointing than an unsalted pretzel\",\"this model makes onions cry\",\"did you get this model from Joe?\",\"remember, these stats aren't an insult, they're just describing your model\",\"this model reminds me - I gotta take out the trash\",\"don't worry - the first 40 years of modeling are always the hardest\",\"this model has miles to go before it reaches mediocre\",\"the bad model store called. they're running out of your models\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-15T20:27:56.667284Z",
     "start_time": "2021-11-15T20:27:48.656818Z"
    }
   },
   "outputs": [],
   "source": [
    "conda env export > environment_2.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:01:39.171956Z",
     "start_time": "2021-11-22T22:01:38.913648Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples before removing empty cells: 65\n",
      "Removing 0 samples.\n",
      "Shape X: (65, 961)\n",
      "Shape y: (65,)\n",
      "Shape labels: (65,)\n",
      "First X cell: 228.2\n",
      "Last X cell:  0.010000000000000231\n",
      "First y: -1.4836863905532456\n",
      "Last y:  -0.996746917\n",
      "Last label: gluER-T36A-Y343W-5a\n"
     ]
    }
   ],
   "source": [
    "# all data in a single file\n",
    "excel_file =\"aMD_with_IFD_010822\" \n",
    "excel_sheet = \"ddG\" #\"singlesub\" #\"no_NH_no_diffaryl\" \n",
    "num_par = 961  \n",
    "par_start_col = 2 #4  # 0-indexed\n",
    "num_samples = 65 \n",
    "response_col = 1 #2   # 0-indexed\n",
    "y_label_col = 0    # 0-indexed\n",
    "\n",
    "apply_mask = True # remove samples with empty response\n",
    "verbose = True\n",
    "xlabelrow = True\n",
    "\n",
    "\n",
    "inp = pd.read_excel(excel_file+\".xlsx\",excel_sheet,header=0,index_col=y_label_col,nrows=num_samples+int(xlabelrow),\n",
    "                    usecols=list(range(0,(num_par+par_start_col))))\n",
    "\n",
    "if xlabelrow:\n",
    "    X_names = list(inp.iloc[0,par_start_col-1:num_par+par_start_col-1]) \n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1] \n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "    inp.drop(index=inp.index[0],inplace=True)\n",
    "else:\n",
    "    X_labels = list(inp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "    X_names = X_labels\n",
    "    resp_label = list(inp.columns)[response_col-1]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "y = np.asarray(inp[resp_label],dtype=np.float)\n",
    "X = np.asarray(inp[X_labels],dtype=np.float)\n",
    "y_labels = np.asarray(list(inp.index),dtype=str)\n",
    "y_labels_comp= y_labels\n",
    "\n",
    "if apply_mask:\n",
    "    mask = y.nonzero()[0]\n",
    "    mask = ~np.isnan(y)\n",
    "    print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "    print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "    X = X[np.array(mask)]\n",
    "    y = y[np.array(mask)]\n",
    "    y_labels = y_labels[np.array(mask)]\n",
    "X_all = X\n",
    "if verbose:\n",
    "    print(\"Shape X: {}\".format(X.shape))\n",
    "    print(\"Shape y: {}\".format(y.shape)) \n",
    "    print(\"Shape labels: {}\".format(y_labels.shape)) \n",
    "    print(\"First X cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label: {}\".format(y_labels[-1]))\n",
    "    #print(inp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-10T22:35:17.471142Z",
     "start_time": "2020-11-10T22:35:02.207032Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## separate files for exp data and comp data\n",
    "\n",
    "comp_file = \"Phosphine_library_DFT_props_191120_copy\" \n",
    "comp_sheet = \"selprops_use_2_bowls\" \n",
    "num_par = 182 \n",
    "par_start_col = 1   # 0-indexed\n",
    "comp_num_samples = 1359 \n",
    "y_label_col_comp = 0  # 0-indexed\n",
    "\n",
    "exp_file = \"exp_bowls\" \n",
    "exp_sheet = \"Sheet1\"\n",
    "exp_num_samples = 10 \n",
    "response_col = 9  # 0-indexed\n",
    "y_label_col_exp = 0  # 0-indexed\n",
    "\n",
    "compinp = pd.read_excel(comp_file+\".xlsx\",comp_sheet,header=0,index_col=y_label_col_comp,nrows=comp_num_samples+1,usecols=list(range(0,(num_par+par_start_col))))\n",
    "compinp.index = compinp.index.map(str)\n",
    "expinp = pd.read_excel(exp_file+\".xlsx\",exp_sheet,header=4,index_col=y_label_col_exp,nrows=exp_num_samples,usecols=list(range(0,response_col+1)))\n",
    "expinp.index = [i.zfill(4) for i in expinp.index.map(str)]\n",
    "\n",
    "xlabelrow = True\n",
    "verbose = True\n",
    "\n",
    "X_names = list(compinp.iloc[0,par_start_col-1:num_par+par_start_col-1])\n",
    "X_labels = list(compinp.columns)[par_start_col-1:num_par+par_start_col-1]\n",
    "compinp.drop(index=compinp.index[0],inplace=True)\n",
    "X_all = np.asarray(compinp[X_labels],dtype=np.float)\n",
    "y_labels_comp = np.asarray(list(compinp.index),dtype=str)\n",
    "compnan = np.isnan(X_all).any(axis=1)\n",
    "y_labels_comp,X_all = y_labels_comp[~compnan],X_all[~compnan]\n",
    "\n",
    "X_labelname = [\" \".join(i) for i in zip(X_labels,X_names)] \n",
    "X_labelname_dict = dict(zip(X_labels,X_names))\n",
    "\n",
    "resp_label = list(expinp.columns)[response_col-1]\n",
    "y = np.asarray(expinp.iloc[:,response_col-1],dtype=np.float)\n",
    "y_labels_exp = np.asarray(list(expinp.index),dtype=str)\n",
    "\n",
    "mask_y = y.nonzero()[0]\n",
    "mask_y = ~np.isnan(y)\n",
    "mask_X = np.array([True if i in y_labels_comp else False for i in y_labels_exp])\n",
    "mask = mask_y&mask_X\n",
    "print(\"n_samples before removing empty cells: {}\".format(len(y)))\n",
    "print(\"Removing {} samples.\".format(len(y)-sum(mask)))\n",
    "y = y[np.array(mask)]\n",
    "y_labels = y_labels_exp[np.array(mask)]\n",
    "\n",
    "X = np.asarray(compinp.loc[y_labels],dtype=np.float)\n",
    "\n",
    "if verbose:\n",
    "    print(\"Shape X (all): {}\".format(X_all.shape))\n",
    "    print(\"Shape X (exp): {}\".format(X.shape))\n",
    "    print(\"Shape y (exp): {}\".format(y.shape)) \n",
    "    print(\"Shape labels (exp): {}\".format(y_labels.shape)) \n",
    "    print(\"First X (exp) cell: {}\".format(X[0,0]))\n",
    "    print(\"Last X (exp) cell:  {}\".format(X[-1,-1]))\n",
    "    print(\"First y: {}\".format(y[0]))\n",
    "    print(\"Last y:  {}\".format(y[-1]))\n",
    "    print(\"Last label exp: {}\".format(y_labels[-1]))\n",
    "    print(\"Last label comp: {}\".format(y_labels_comp[-3:]))\n",
    "    #print(inp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms and univariate correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T20:57:55.527600Z",
     "start_time": "2021-11-08T20:56:27.638541Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original data\n",
    "# Visualize Histograms and univariate correlations for all (or selected) features\n",
    "features = range(np.shape(X)[1])   # iterate over all features\n",
    "# examples for selecting features\n",
    "#specify names:\n",
    "# features = [x_names.index(\"sterimol_5-.5cB5_max\")]\n",
    "#specify x-numbers (1-indexed):\n",
    "#features_x = [\"x139\",\"x140\",\"x141\",\"x142\",\"x143\",\"x144\",\"x145\",\"x146\",\"x147\",\"x148\",\"x149\",\"x150\",\"x151\",\"x152\",\"x153\",\"x154\",\"x155\",\"x156\",\"x157\",\"x158\",\"x159\",\"x160\",\"x161\",\"x162\",\"x163\"]\n",
    "#features = [X_labels.index(i) for i in features_x]\n",
    "#specify ranges (0-indexed)\n",
    "#features = itertools.chain(range(15,92)) #480,2611)) #312,343)) \n",
    "\n",
    "for f_ind in features:\n",
    "    feature = X_labels[f_ind]\n",
    "    print(feature, X_names[f_ind])\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,f_ind], y)\n",
    "    fit_line = intercept+slope*X[:,f_ind]\n",
    "    \n",
    "    plt.figure(figsize=(9, 4))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.hist(X[:,f_ind], bins=\"auto\")\n",
    "    plt.ylabel(\"frequency\",fontsize=20)\n",
    "    plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=20)\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(X[:,f_ind], y,color=\"black\",marker=\"s\",alpha=0.5)    \n",
    "    plt.plot(X[:,f_ind],fit_line,color=\"black\")\n",
    "    plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=20)\n",
    "    plt.ylabel(\"y\",fontsize=20) # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "#     plt.xticks(np.arange(round(min(X[:,f_ind])-0.005,3), round(max(X[:,f_ind])+0.005,3), 0.03),fontsize=15)\n",
    "    plt.yticks(fontsize=15)        \n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n",
    "\n",
    "    if p_value > 0.01:\n",
    "        print(\"R^2 = {:.2f}; p-value = {:.2f}\".format(r_value**2,p_value))\n",
    "    else:\n",
    "        print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "    print(\"\\n-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:00:33.281767Z",
     "start_time": "2021-11-08T21:00:32.125067Z"
    }
   },
   "outputs": [],
   "source": [
    "# has option to only print univariate correlations if they meet an R^2 cutoff\n",
    "\n",
    "### All features:\n",
    "features = range(np.shape(X)[1])\n",
    "### Features by X-numbers (1-indexed):\n",
    "#features_x = [\"x1\",\"x19\",\"x20\",\"x31\",\"x120\",\"x145\",\"x160\"]\n",
    "#features_x = [\"x231\"]\n",
    "#features = [X_labels.index(i) for i in features_x]\n",
    "### Feature by range (0-indexed):\n",
    "# features = itertools.chain(range(75,85),range(90,95))\n",
    "\n",
    "#set r2 cutoff\n",
    "r2_cutoff = 0.4\n",
    "r2_values = []\n",
    "\n",
    "for f_ind in features:\n",
    "    feature = X_labels[f_ind]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,f_ind], y)\n",
    "    fit_line = intercept+slope*X[:,f_ind]\n",
    "    r2 = r_value**2\n",
    "    r2_values.append(r2)\n",
    "    if r2 >= r2_cutoff:\n",
    "        print(feature, X_names[f_ind])\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.hist(X[:,f_ind], bins=\"auto\")\n",
    "        plt.ylabel(\"frequency\",fontsize=12)\n",
    "        plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.set_style(\"white\")\n",
    "        sns.regplot(X[:,f_ind],y,ci=95,truncate=False)\n",
    "        x_max=np.max(X[:,f_ind])\n",
    "        x_min=np.min(X[:,f_ind])\n",
    "        y_max=np.max(y)\n",
    "        y_min=np.min(y)\n",
    "        delta_x = 0.05 * (x_max-x_min)\n",
    "        delta_y = 0.05 * (y_max-y_min)\n",
    "        plt.xlim([x_min-delta_x,x_max+delta_x])\n",
    "        plt.ylim([y_min-delta_y,y_max+delta_y])\n",
    "        #plt.scatter(X[:,f_ind], y,color=\"black\",marker=\".\",alpha=0.5,s=150)\n",
    "        #plt.plot(X[:,f_ind],fit_line,color=\"black\")\n",
    "        plt.xlabel(feature + \" \" + X_names[f_ind],fontsize=18)\n",
    "        plt.ylabel(\"y\",fontsize=18)  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "        plt.xticks(fontsize=14)\n",
    "        plt.yticks(fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        #toggle these two lines to either show or show and save the plots\n",
    "        plt.show()\n",
    "        #plt.savefig(\"plotname.png\",dpi=300)\n",
    "        \n",
    "        if p_value > 0.01:\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2f}\".format(r_value**2,p_value))\n",
    "        else:\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "        print(\"\\n--------------------------------------------------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot a feature vs. another feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:04:06.733261Z",
     "start_time": "2021-11-08T21:04:06.114915Z"
    }
   },
   "outputs": [],
   "source": [
    "# one comparison plot at a time\n",
    "\n",
    "# select two features to visualize\n",
    "# can be integer-index of features, or string with x-number\n",
    "f_ind_1 = \"x171\"\n",
    "f_ind_2 = \"x71\"\n",
    "\n",
    "if type(f_ind_1) == str:\n",
    "    [f_ind_1,f_ind_2] = [X_labels.index(i) for i in [f_ind_1,f_ind_2]]\n",
    "\n",
    "print(X_labels[f_ind_1], X_names[f_ind_1])\n",
    "print(X_labels[f_ind_2], X_names[f_ind_2])\n",
    "print(\"\\n{} samples\".format(np.shape(X[:,f_ind_1])[0]))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,f_ind_1],X[:,f_ind_2])\n",
    "fit_line = intercept+slope*X[:,f_ind_1]\n",
    "print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "\n",
    "plt.figure(figsize=(13, 4))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.hist(X[:,f_ind_1], bins=\"auto\",color=\"black\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(X_labels[f_ind_1] + \" \" + X_names[f_ind_1])\n",
    "plt.subplot(1,3,2)\n",
    "plt.hist(X[:,f_ind_2], bins=\"auto\",color=\"black\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.xlabel(X_labels[f_ind_2] + \" \" + X_names[f_ind_2])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.scatter(X[:,f_ind_1], X[:,f_ind_2],color=\"black\",marker=\"s\")    \n",
    "#plt.plot(X[:,f_ind_1],fit_line)\n",
    "plt.xlabel(X_labels[f_ind_1] + \" \" + X_names[f_ind_1])\n",
    "plt.ylabel(X_labels[f_ind_2] + \" \" + X_names[f_ind_2])\n",
    "plt.tight_layout()\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:11:52.526082Z",
     "start_time": "2021-11-08T21:11:40.925395Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multpile plots set by ranges\n",
    "# shows only plots as set by criteria below\n",
    "\n",
    "feats_to_check1 = itertools.chain(range(48,49),range(72,73)) \n",
    "feats_to_check2 = range(150,190) \n",
    "\n",
    "for i in feats_to_check1:\n",
    "    num1 = i\n",
    "    x_format1 = \"x{}\".format(num1 + 1)\n",
    "    if type(x_format1) == str:\n",
    "            [x_format1] = [X_labels.index(i) for i in [x_format1]]\n",
    "    for p in feats_to_check2:\n",
    "        num2 = p\n",
    "        x_format2 = \"x{}\".format(num2)\n",
    "        \n",
    "        #---\n",
    "        if type(x_format2) == str:\n",
    "            [x_format2] = [X_labels.index(i) for i in [x_format2]]\n",
    "        #print(i,x_format1,type(x_format1))\n",
    "        #print(p,x_format2,type(x_format2))\n",
    "\n",
    "        if x_format1 != x_format2:\n",
    "            print(X_labels[x_format1], X_names[x_format1])\n",
    "            print(X_labels[x_format2], X_names[x_format2])\n",
    "            print(\"\\n{} samples\".format(np.shape(X[:,x_format1])[0]))\n",
    "            slope, intercept, r_value, p_value, std_err = stats.linregress(X[:,x_format1],X[:,x_format2])\n",
    "            fit_line = intercept+slope*X[:,x_format1]\n",
    "            print(\"R^2 = {:.2f}; p-value = {:.2E}\".format(r_value**2,p_value))\n",
    "            \n",
    "            #show only plots satisfying these criteria:\n",
    "            if r_value > 0.2:\n",
    "                plt.figure(figsize=(13, 4))\n",
    "                \n",
    "                plt.subplot(1,3,1)\n",
    "                plt.hist(X[:,x_format1], bins=\"auto\",color=\"black\")\n",
    "                plt.ylabel(\"frequency\")\n",
    "                plt.xlabel(X_labels[x_format1] + \" \" + X_names[x_format1])\n",
    "                plt.subplot(1,3,2)\n",
    "                plt.hist(X[:,x_format2], bins=\"auto\",color=\"black\")\n",
    "                plt.ylabel(\"frequency\")\n",
    "                plt.xlabel(X_labels[x_format2] + \" \" + X_names[x_format2])\n",
    "                \n",
    "                plt.subplot(1,3,3)\n",
    "                plt.scatter(X[:,x_format1], X[:,x_format2],color=\"black\",marker=\"s\")    \n",
    "                #plt.plot(X[:,f_ind_1],fit_line)\n",
    "                \n",
    "                # label by x number\n",
    "                #plt.xlabel(X_labels[num1])\n",
    "                #plt.ylabel(X_labels[num2])\n",
    "                # label by x name           \n",
    "                plt.xlabel(X_labels[x_format1] + \" \" + X_names[x_format1])\n",
    "                plt.ylabel(X_labels[x_format2] + \" \" +X_names[x_format2])\n",
    "                plt.tight_layout()\n",
    "            \n",
    "            \n",
    "                plt.show()   \n",
    "                \n",
    "            print(\"\\n---------------------------------------------------------------------------------------------------------------\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bubble Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parm v parm, sized by y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T22:23:43.345949Z",
     "start_time": "2021-11-22T22:23:43.182536Z"
    }
   },
   "outputs": [],
   "source": [
    "# set x, y, and size dimensions, set plot title\n",
    "bp_x = \"x49\"\n",
    "bp_y = \"x73\"\n",
    "#bp_size = \"s2_3.5h_%yield(avg)\"\n",
    "#bp_title = \"parm v parm sized by y\"\n",
    "\n",
    "\n",
    "#figure size\n",
    "plt.figure(figsize=(8,8))\n",
    "# use the scatterplot function to build the bubble map\n",
    "sns.scatterplot(data=inp, \n",
    "                x=bp_x,                   #set x\n",
    "                y=bp_y,                   #set y\n",
    "                size=bp_size,             #set size\n",
    "                sizes=(50, 300),          #set size range\n",
    "                alpha=0.7,                #set transparency\n",
    "                color=\"mediumslateblue\",  #set color of points\n",
    "                marker=\"D\")               #set marker shape\n",
    "\n",
    "#toggle this to label data points with IDs\n",
    "#for i in range(0,inp.shape[0]):\n",
    "#    plt.text(inp[bp_x][i]-0.002, inp[bp_y][i]+0.0001, inp.index[i], size=\"small\")\n",
    "    \n",
    "#set x,y limits, place legend outside of plot, set title\n",
    "plt.xlim((round(min(inp[bp_x]),2)-0.01),(round(max(inp[bp_x]),2)+0.01)) \n",
    "plt.ylim((round(min(inp[bp_y]),2)-0.01),(round(max(inp[bp_y]),2)+0.01))\n",
    "plt.legend(bbox_to_anchor=(1.01,1),loc=2,borderaxespad=0)\n",
    "plt.title(bp_title)\n",
    "\n",
    "# show or save the graph\n",
    "plt.show()\n",
    "#plt.savefig(\"plotname\",format=png,dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with virtual entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-22T21:53:30.219589Z",
     "start_time": "2021-11-22T21:53:30.032697Z"
    }
   },
   "outputs": [],
   "source": [
    "#plots exp entires by size and virtual entries on top with different marker\n",
    "#requires a column labeled \"virtual\" with 1=virtual structure, 0=experimental structure. put 0s in the ycolumns for these\n",
    "\n",
    "# set x, y, and size dimensions, set plot title\n",
    "bp_x = \"x49\"\n",
    "bp_y = \"x73\"\n",
    "bp_size = \"s2_3.5h_%yield(avg)\"\n",
    "bp_title = \"parm v parm sized by y\"\n",
    "#set colors for exp (0) and virtual (1)\n",
    "palette = {0:\"tomato\",\n",
    "           1:\"royalblue\"}\n",
    "\n",
    "#figure size\n",
    "plt.figure(figsize=(8,8))\n",
    "# use the scatterplot function to build the bubble map\n",
    "sns.scatterplot(data=bp_df, \n",
    "                x=bp_x,                   #set x\n",
    "                y=bp_y,                   #set y\n",
    "                size=bp_size,             #set size\n",
    "                sizes=(50, 500),          #set size range\n",
    "                alpha=0.7,                #set transparency\n",
    "                hue=inp['virtual'],       #color points by virtual or exp\n",
    "                style=inp['virtual'],     #set point markers by virtual or exp\n",
    "                palette=palette)          #use defined colors\n",
    "\n",
    "#toggle this to label data points or not\n",
    "#for i in range(0,inp.shape[0]):\n",
    "#    plt.text(inp[bp_x][i]+0.0002, inp[bp_y][i], inp.index[i], size=\"small\")\n",
    "\n",
    "#set x,y limits, place legend outside of plot, set title\n",
    "plt.xlim((round(min(inp[bp_x]),2)-0.005),(round(max(inp[bp_x]),2)+0.005)) \n",
    "plt.ylim((round(min(inp[bp_y]),2)-0.005),(round(max(inp[bp_y]),2)+0.005))\n",
    "plt.legend(bbox_to_anchor=(1.01,1),loc=2,borderaxespad=0)\n",
    "plt.title(bp_title)\n",
    "\n",
    "# show or save the graph\n",
    "plt.show()\n",
    "#plt.savefig(\"plotname\",format=png,dpi=300)\n",
    "\n",
    "print(\"note: virtual ligands sized arbitrarily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:04:28.743501Z",
     "start_time": "2021-11-03T22:04:26.819738Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# uncomment this line to use an interactive plot \n",
    "# %matplotlib notebook\n",
    "\n",
    "corrmap = np.corrcoef(X.T)\n",
    "\n",
    "plt.matshow(corrmap)\n",
    "plt.xticks(range(len(X_labels)),X_labels, fontsize=10, rotation=90)\n",
    "plt.yticks(range(len(X_labels)),X_labels, fontsize=10)\n",
    "cb = plt.colorbar()\n",
    "cb.ax.tick_params(labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:04:33.402043Z",
     "start_time": "2021-11-03T22:04:28.980867Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# uncomment this line to use an interactive plot \n",
    "#%matplotlib notebook\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "corrmap = np.corrcoef(X.T)\n",
    "\n",
    "plt.subplots(figsize=(15,15))\n",
    "sns.heatmap(corrmap,center=0, annot=False, cmap=\"coolwarm\", cbar=True) #linewidths=0.5\n",
    "plt.xticks(range(len(X_labels)),X_labels, fontsize=10, rotation=90)\n",
    "plt.yticks(range(len(X_labels)),X_labels, fontsize=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-node Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:05:24.703822Z",
     "start_time": "2021-11-03T22:05:24.542255Z"
    }
   },
   "outputs": [],
   "source": [
    "# import graphviz \n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth=1).fit(X, y)\n",
    "print(\"Accuracy: {:.2f}\".format(dt.score(X, y)))\n",
    "\n",
    "feat = int(np.where(dt.feature_importances_ != 0)[0])\n",
    "print(X_labels[feat],X_names[feat])\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.scatter(X[:,feat], y)    \n",
    "plt.xlabel(X_names[feat])\n",
    "plt.ylabel(\"y\")  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "# dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "#                      feature_names=X_names,   \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify highest and lowest group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:05:27.330641Z",
     "start_time": "2021-11-03T22:05:26.828983Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find features that separate the group with highest/lowest output y\n",
    "# change the definition of bins in the histogram to get control over how these groups are defined\n",
    "y_hist,y_bin_edges = np.histogram(y,bins=\"auto\")\n",
    "y_class_low = [0 if i < y_bin_edges[1] else 1 for i in y]\n",
    "y_class_high = [1 if i > y_bin_edges[-2] else 0 for i in y]\n",
    "\n",
    "plt.figure(figsize=(8.5, 4))\n",
    "n_classes = 2\n",
    "plot_colors = \"rg\"\n",
    "plot_step = 0.02\n",
    "y_classes = [np.asarray(y_class_low),np.asarray(y_class_high)]\n",
    "for y_class,i in zip(y_classes,[1,2]):\n",
    "    dt = DecisionTreeClassifier(max_depth=1).fit(X, y_class)\n",
    "    feat = int(np.where(dt.feature_importances_ != 0)[0])    \n",
    "    a = (\"f1_score: {:.2f}\".format(metrics.f1_score(y_class,dt.predict(X))))\n",
    "#    b = (\"auc: {:.2f}\".format(metrics.roc_auc_score(y_class,dt.predict(X))))\n",
    "    print(X_labels[feat],X_names[feat])    \n",
    "    xpltlabel = X_labels[feat] + \"\\n\" + X_names[feat] + \"\\n\" + a# + \"\\n\" + b\n",
    "\n",
    "    dt_plt = DecisionTreeClassifier(max_depth=1).fit(X[:,feat].reshape(-1, 1), y_class)\n",
    "    x_min, x_max = X[:, feat].min(), X[:, feat].max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    dx,dy = x_max-x_min,y_max-y_min\n",
    "    xx, yy = np.meshgrid(np.arange(x_min-0.04*dx, x_max+0.04*dx, plot_step),\n",
    "                         np.arange(y_min-0.04*dy, y_max+0.04*dy, plot_step))\n",
    "    \n",
    "    plt.subplot(1,2,i)\n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = dt_plt.predict(xx.ravel().reshape(-1, 1))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=\"Pastel1\")#plt.cm.RdYlBu)\n",
    "\n",
    "    plt.xlabel(xpltlabel)\n",
    "    plt.ylabel(\"y\")\n",
    "\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_class == i)\n",
    "        plt.scatter(X[idx, feat], y[idx], c=color,cmap=plt.cm.RdYlBu, edgecolor='black', s=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# dot_data = tree.export_graphviz(dt_plt, out_file=None, \n",
    "#                      feature_names=[x_names[feat]],   \n",
    "#                      filled=True, rounded=True,  \n",
    "#                      special_characters=True)  \n",
    "# graph = graphviz.Source(dot_data)\n",
    "# graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-07T03:12:00.181835Z",
     "start_time": "2019-07-07T03:12:00.176867Z"
    }
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:05:37.140233Z",
     "start_time": "2021-11-03T22:05:36.941768Z"
    }
   },
   "outputs": [],
   "source": [
    "# divide samples into two classes based on y_cut, find the feature that most clearly distinguishes these groups\n",
    "y_cut = 50\n",
    "\n",
    "#this can be done on a subset of features\n",
    "# features = [i for i in itertools.chain(range(75,85),range(90,95))]\n",
    "# features = [i for i in range(38,135)]\n",
    "features = range(np.shape(X)[1])\n",
    "X_use = X[:,features]\n",
    "\n",
    "y_class = np.array([0 if i < y_cut else 1 for i in y])\n",
    "n_classes=2\n",
    "dt = DecisionTreeClassifier(max_depth=1).fit(X_use, y_class)\n",
    "\n",
    "feat = features[int(np.where(dt.feature_importances_ != 0)[0])]\n",
    "print(X_labels[feat],X_names[feat])\n",
    "\n",
    "dt_plt = DecisionTreeClassifier(max_depth=1).fit(X[:,feat].reshape(-1, 1), y_class)\n",
    "print(\"Decision threshold = {:.2f}\\nAccuracy: {:.2f}\\nf1_score: {:.2f}\\nN = {}\".format(\n",
    "        dt_plt.tree_.threshold[0],\n",
    "        dt_plt.score(X[:,feat].reshape(-1, 1), y_class),\n",
    "        metrics.f1_score(y_class,dt_plt.predict(X[:,feat].reshape(-1, 1))),\n",
    "        len(y)\n",
    "    ))\n",
    "\n",
    "plot_colors = \"rg\"\n",
    "plot_step = 0.02\n",
    "x_min, x_max = X[:,feat].min(), X[:,feat].max()\n",
    "y_min, y_max = y.min(), y.max()\n",
    "dx,dy = x_max-x_min,y_max-y_min\n",
    "xx, yy = np.meshgrid(np.arange(x_min-0.04*dx, x_max+0.04*dx, plot_step),\n",
    "                     np.arange(y_min-0.04*dy, y_max+0.04*dy, plot_step))\n",
    "\n",
    "plt.figure(figsize=(4, 4))    \n",
    "plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "Z = dt_plt.predict(xx.ravel().reshape(-1, 1))\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap=\"Pastel1\")#plt.cm.RdYlBu)\n",
    "xpltlabel = X_labels[feat] + \"\\n\" + X_names[feat]\n",
    "\n",
    "plt.xlabel(xpltlabel)\n",
    "plt.ylabel(\"y\")  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(y_class == i)\n",
    "    plt.scatter(X[idx, feat], y[idx], c=color,cmap=plt.cm.RdYlBu, edgecolor='black', s=15)    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:07:48.116503Z",
     "start_time": "2021-11-03T22:07:46.199886Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for public threshold script, see https://github.com/SigmanGroup/Threshold\n",
    "\n",
    "# divide samples into two classes based on y_cut, visualize how features separate these classes\n",
    "y_cut = 50\n",
    "class_weight = {0:1,1:20}\n",
    "\n",
    "#select features here\n",
    "features = range(len(X_labels))   # iterate over all features\n",
    "#features = itertools.chain(range(7,20))\n",
    "\n",
    "y_class = np.array([0 if i < y_cut else 1 for i in y])\n",
    "n_classes = 2\n",
    "plot_colors = \"rg\"\n",
    "plot_step = 0.02 #0.002\n",
    "\n",
    "for f_ind in features:\n",
    "    feature = X_labels[f_ind]\n",
    "    print(feature, X_names[f_ind])\n",
    "    dt = DecisionTreeClassifier(max_depth=1,class_weight=class_weight).fit(X[:,f_ind].reshape(-1, 1), y_class)\n",
    "    print(\"Decision threshold = {:.2f}\\nAccuracy: {:.2f}\\nf1_score: {:.2f}\\nN = {}\".format(\n",
    "        dt.tree_.threshold[0],\n",
    "        dt.score(X[:,f_ind].reshape(-1, 1), y_class),\n",
    "        metrics.f1_score(y_class,dt.predict(X[:,f_ind].reshape(-1, 1))),\n",
    "        len(y)\n",
    "    ))\n",
    "    \n",
    "    dt_plt = DecisionTreeClassifier(max_depth=1).fit(X[:,f_ind].reshape(-1, 1), y_class)\n",
    "    x_min, x_max = X[:,f_ind].min(), X[:,f_ind].max()\n",
    "    y_min, y_max = y.min(), y.max()\n",
    "    dx,dy = x_max-x_min,y_max-y_min\n",
    "    xx, yy = np.meshgrid(np.arange(x_min-0.04*dx, x_max+0.04*dx, plot_step),\n",
    "                         np.arange(y_min-0.04*dy, y_max+0.04*dy, plot_step))\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))    \n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)\n",
    "\n",
    "    Z = dt_plt.predict(xx.ravel().reshape(-1, 1))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=\"Pastel1\")#plt.cm.RdYlBu)\n",
    "    xpltlabel = X_labels[f_ind] + \"\\n\" + X_names[f_ind]\n",
    "\n",
    "    plt.xlabel(xpltlabel)\n",
    "    plt.ylabel(\"y\")  # \"$ΔΔG^{≠}$\"  \"Yield\"\n",
    "\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y_class == i)\n",
    "        plt.scatter(X[idx, f_ind], y[idx], c=color,cmap=plt.cm.RdYlBu, edgecolor='black', s=15)    \n",
    "    \n",
    "    #plt.savefig(name,dpi=300,bbox_inches = 'tight')\n",
    "\n",
    "    plt.show()\n",
    "    print(\"\\n----------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation: Training/Test set split, Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T10:58:43.936962Z",
     "start_time": "2020-11-23T10:58:43.924995Z"
    }
   },
   "outputs": [],
   "source": [
    "# if you need to do a lot of math on this - hanna generally does not use\n",
    "# perform transformations on y\n",
    "y_orig = y.copy() # this is a backup of y\n",
    "\n",
    "#toggle these options to manipulate y\n",
    "\n",
    "#exp\n",
    "# y = np.exp(y_orig)\n",
    "\n",
    "#log-transformation: either remove all samples with y=0 () or add a small amount to y to avoid log(0).\n",
    "#y = np.log(y+0.0001)\n",
    "#or\n",
    "#y = np.log(y[y.nonzero()[0]])\n",
    "# y_labels_orig,X_orig = y_labels.copy(),X.copy()\n",
    "# y_labels = y_labels[y.nonzero()[0]]\n",
    "# X = X[y.nonzero()[0]]\n",
    "\n",
    "#absolute value\n",
    "# y = abs(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T22:17:11.312050Z",
     "start_time": "2021-09-23T22:17:11.305037Z"
    }
   },
   "outputs": [],
   "source": [
    "# preselection option 1\n",
    "# comment-out first line in Train/test split if using this\n",
    "\n",
    "# remove samples based on a feature-value \n",
    "select_feature = \"x79\" \n",
    "\n",
    "# define cutoff \n",
    "mask_prop = X[:,X_labels.index(select_feature)]<5.62   \n",
    "\n",
    "X_sel,y_sel,y_labels_sel = X[mask_prop],y[mask_prop],y_labels[mask_prop]\n",
    "print(\"Shape X: {}\".format(X_sel.shape))\n",
    "print(\"Shape y: {}\".format(y_sel.shape)) \n",
    "print(\"Shape labels: {}\".format(y_labels_sel.shape)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T17:14:00.823514Z",
     "start_time": "2020-01-10T17:14:00.819555Z"
    }
   },
   "outputs": [],
   "source": [
    "# preselection - used to exclude certain things from training/test\n",
    "# comment-out first line in Train/test split if using this\n",
    "\n",
    "# remove samples based on index (0-indexed)\n",
    "\n",
    "exclude = [38] #+[i for i in range(26,37)]\n",
    "print(exclude)\n",
    "mask = [i for i in range(len(y)) if i not in exclude]\n",
    "X_sel,y_sel,y_labels_sel = X[mask],y[mask],y_labels[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Test set split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T20:09:20.635784Z",
     "start_time": "2021-11-23T20:09:20.462241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TS: [51, 58, 20, 16, 37, 10, 61, 27, 13, 47, 43, 49, 11, 6, 44, 55, 39, 22, 62, 36, 53, 64, 57, 38, 17, 48, 24, 34, 12, 52, 46, 23, 8, 14, 1, 15, 56, 4, 35, 21, 31, 32, 60, 3, 30]\n",
      "VS: [28, 29, 63, 42, 5, 41, 40, 54, 59, 33, 45, 19, 18, 25, 26, 50, 0, 7, 2, 9]\n",
      "y_mean TS: -0.896\n",
      "y_mean VS: -0.887\n",
      "Shape X_train: (45, 961)\n",
      "Shape X_test:  (20, 961)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# comment this line out if preselection was performed\n",
    "X_sel,y_sel,labels_sel,exclude = X,y,y_labels,[]\n",
    "\n",
    "# select method of split:\n",
    "# random\n",
    "# y_equidist - picks points that evenly span the output variable y. \n",
    "#              Normally doesn't pick highest/lowest values but this can be activated by changing the variable no_extrapolation in the respective section\n",
    "# ks - Kennard Stone algorithm picks points based on an even distriution in feature space\n",
    "# define - give a list of sample indices for either VS or TS in the corresponding code section \n",
    "# none - all samples in TS\n",
    "\n",
    "# the numbers in the variables VS and TS refer to the original 0-indexed sample numbers \n",
    "\n",
    "split = \"random\"\n",
    "test_ratio = 0.3 # means 70% in training set\n",
    "\n",
    "if split == \"random\":\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sel, y_sel, random_state=randomstate+3, test_size=test_ratio)    \n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]\n",
    "    \n",
    "elif split == \"define\":\n",
    "   # numbers according to sample lines in the excel sheet (that is, including indexes of 'excluded' samples)\n",
    "    # for defining the TS, change the names of TS and VS in the next three lines\n",
    "    #TS = [16,27,25,5,13,9,29,7]\n",
    "    TS = []\n",
    "    VS = [16,27,25,5,13,9,29,7]\n",
    "    #TS = [i-1 for i in VS] # this can be commented out if 0-indexed numbers were defined above\n",
    "    #VS = [i for i in range(X.shape[0]) if i not in VS and i not in exclude]\n",
    "    TS = [i for i in range(X.syhape[0]) if i not in VS and i not in exclude]\n",
    "    X_train, y_train,X_test, y_test = X[TS],y[TS],X[VS],y[VS]\n",
    "    \n",
    "elif split == \"ks\":\n",
    "    import kennardstonealgorithm as ks\n",
    "    TS,VS = ks.kennardstonealgorithm(X_sel,int((1-test_ratio)*np.shape(X_sel)[0]))\n",
    "    X_train, y_train,X_test, y_test = X_sel[TS], y_sel[TS],X_sel[VS], y_sel[VS]\n",
    "  \n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]   \n",
    "\n",
    "elif split == \"y_equidist\":\n",
    "    no_extrapolation = True\n",
    "    \n",
    "    import kennardstonealgorithm as ks\n",
    "    if no_extrapolation:\n",
    "        minmax = [np.argmin(y_sel),np.argmax(y_sel)]\n",
    "        y_ks = np.array(([i for i in y_sel if i not in [np.min(y_sel),np.max(y_sel)]]))\n",
    "        y_ks_indices = [i for i in range(len(y_sel)) if i not in minmax]\n",
    "        \n",
    "        # indices relative to y_ks:\n",
    "        VS_ks,TS_ks = ks.kennardstonealgorithm(y_ks.reshape(np.shape(y_ks)[0],1),int((test_ratio)*(2+np.shape(y_ks)[0])))\n",
    "        # indices relative to y_sel:\n",
    "        TS_ = sorted([y_ks_indices[i] for i in list(TS_ks)]+minmax)\n",
    "        VS_ = sorted([y_ks_indices[i] for i in VS_ks])\n",
    "\n",
    "    else:\n",
    "        VS_,TS_ = ks.kennardstonealgorithm(y_sel.reshape(np.shape(y_sel)[0],1),int((test_ratio)*np.shape(y_sel)[0]))\n",
    "    \n",
    "    X_train, y_train,X_test, y_test = X_sel[TS_], y_sel[TS_],X_sel[VS_], y_sel[VS_]\n",
    "    \n",
    "    # indices relative to y\n",
    "    TS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_train]\n",
    "    VS = [np.argwhere(np.all(X==i,axis=1))[0,0] for i in X_test]\n",
    "\n",
    "elif split == \"none\":\n",
    "    TS, VS = [i for i in range(X.shape[0]) if i not in exclude],[]\n",
    "    X_train, y_train,X_test, y_test = X[TS],y[TS],X[VS],y[VS]\n",
    "    \n",
    "else: \n",
    "    raise ValueError(\"split option not recognized\")\n",
    "     \n",
    "\n",
    "print(\"TS: {}\".format(TS))\n",
    "print(\"VS: {}\".format(VS))\n",
    "print(\"y_mean TS: {:.3f}\".format(np.mean(y_train)))\n",
    "print(\"y_mean VS: {:.3f}\".format(np.mean(y_test)))\n",
    "print(\"Shape X_train: {}\".format(X_train.shape))\n",
    "print(\"Shape X_test:  {}\".format(X_test.shape))   \n",
    "plt.figure(figsize=(5, 5))\n",
    "hist,bins = np.histogram(y_sel,bins=\"auto\")#\"auto\"\n",
    "plt.hist(y_train, bins, alpha=0.5, label='y_train',color=\"black\")\n",
    "plt.hist(y_test, bins, alpha=0.5, label='y_test')\n",
    "# plt.legend(loc='best')\n",
    "plt.xlabel(\"y\",fontsize=20)\n",
    "plt.ylabel(\"N samples\",fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-23T20:09:21.883665Z",
     "start_time": "2021-11-23T20:09:21.869702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# scale features by mean/variance, pick the relevant option (normally: StandardScaler)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "X_all_sc = scaler.transform(X_all)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-terms/Interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T19:25:31.104797Z",
     "start_time": "2020-01-07T19:25:30.224203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add polynomial features/interaction terms\n",
    "# this is not yet implemented properly in some sections. \n",
    "# for 5.1-manual selection: specify cross-term with space between the components: x1 x40 + x6\n",
    "# Essentially only section 5.2 can use cross-terms so far\n",
    "# don't run this twice\n",
    "\n",
    "polyfeats = PolynomialFeatures(degree=2,interaction_only=False,include_bias=False)\n",
    "X_train_p = polyfeats.fit_transform(X_train_sc)  #[:,[1,8,0]])\n",
    "X_test_p = polyfeats.transform(X_test_sc)\n",
    "X_all_p = polyfeats.transform(X_all_sc)\n",
    "\n",
    "def add_to_x(matchobj):\n",
    "    if \"^\" in matchobj.group(0):\n",
    "        n = int(matchobj.group(0).split(\"^\")[0])+1\n",
    "        return(\"{} x{}\".format(n,n))\n",
    "    else:\n",
    "        return(str(int(matchobj.group(0))+1))\n",
    "    \n",
    "pfnames = np.asarray([re.sub(\"[0-9]+(\\^[0-9])*\",add_to_x,st) for st in polyfeats.get_feature_names()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-07T19:25:36.477761Z",
     "start_time": "2020-01-07T19:25:33.137640Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter out non-significant crossterms based on p-value with target variable\n",
    "p_val_cutoff = 0.005\n",
    "\n",
    "r2s = []\n",
    "pvals = []\n",
    "for f_ind,feature in enumerate(X_train_p.T):\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(feature, y_train)    \n",
    "    r2s.append(r_value**2)\n",
    "    pvals.append(p_value)\n",
    "    \n",
    "r2s_ = np.asarray(r2s)\n",
    "pvals_ = np.asarray(pvals)\n",
    "\n",
    "keep_p_ = [i[0] for i in np.argwhere(pvals_<p_val_cutoff) if i not in range(np.shape(X_all)[1])]\n",
    "keep_p = [i for i in range(np.shape(X_all)[1])] + keep_p_\n",
    "\n",
    "def sub_label_to_name(matchobj):\n",
    "    return(X_labelname_dict[matchobj.group(0)])\n",
    "def sub_labelname(matchobj):\n",
    "    return(matchobj.group(0)+\" \"+X_labelname_dict[matchobj.group(0)])\n",
    "    \n",
    "pfnames = np.asarray([re.sub(\"[0-9]+(\\^[0-9])*\",add_to_x,st) for st in polyfeats.get_feature_names()])\n",
    "X_p_labels = list(np.reshape(pfnames[keep_p],len(keep_p)))\n",
    "X_p_names = [re.sub(\"x[0-9]+\",sub_label_to_name,st) for st in X_p_labels]\n",
    "X_p_labelname = [re.sub(\"x[0-9]+\",sub_labelname,st) for st in X_p_labels]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "# scaler = MinMaxScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train_p[:,keep_p])\n",
    "X_test_sc = scaler.transform(X_test_p[:,keep_p])\n",
    "X_all_sc = scaler.transform(X_all_p[:,keep_p])\n",
    "\n",
    "X_labels = X_p_labels\n",
    "X_names = X_p_names\n",
    "X_labelname = X_p_labelname\n",
    "\n",
    "print(\"{} cross-terms with p-value < {}\".format(len(keep_p_),p_val_cutoff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear modelling, feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual selection of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-17T22:08:17.244442Z",
     "start_time": "2021-11-17T22:08:16.773061Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#provide an x__ model (string, any order of terms)\n",
    "features_x =  \"x229 + x520 + x598 + x609\"#\n",
    "features_py = sorted([X_labels.index(i.strip()) for i in features_x.split(\"+\")])\n",
    "\n",
    "# features_py = []\n",
    "#features = sorted([int(i[1:]) for i in re.findall(\"x\\d+\",features_x)])\n",
    "#features_py = [i-1 for i in features]\n",
    "\n",
    "\n",
    "X_train_sel = X_train_sc[:,features_py]\n",
    "X_test_sel = X_test_sc[:,features_py]\n",
    "lr = Ridge(alpha=1E-5).fit(X_train_sel, y_train)\n",
    "\n",
    "#lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "alphas = np.logspace(-6,3,10)\n",
    "\n",
    "#for i in alphas:\n",
    "#lr = Ridge(alpha=i).fit(X_train_sel, y_train)     \n",
    "#print(f'\\nalpha: {i}')\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores = repeated_k_fold(X_train_sel,y_train,k=5,n=200)\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(features_py)[i]]) for i in range(len(features_py))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores.mean(), kfoldscores.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "\n",
    "# settings for plot and saving\n",
    "#plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=\"plotname\",label=\"$ΔΔG^{≠}$\",loo_pred=loo_train)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=True,sav=False,label=\"Yield\",loo_pred=loo_train)\n",
    "    \n",
    "\n",
    "model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "#print(model.summary())\n",
    "\n",
    "print (y_pred_test) #prints out all predicted y values in a list - can also do this on training set\n",
    "print (y_test) #prints experimental values\n",
    "print(y_pred_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:45:06.041580Z",
     "start_time": "2021-11-03T22:45:04.231435Z"
    }
   },
   "outputs": [],
   "source": [
    "# add all individual features to the manual model\n",
    "add_df = pd.DataFrame(index=X_labelname,columns=[\"label_sep\",\"label_abs\",\"Training R2\",\"Training Q2\"],dtype=float)\n",
    "\n",
    "update_model = False\n",
    "for f_ind in range(len(X_labels)):\n",
    "    features_iter = features_py + [f_ind]    \n",
    "    X_train_sel = X_train_sc[:,features_iter]\n",
    "    X_test_sel = X_test_sc[:,features_iter]\n",
    "    # lr = Ridge(alpha=1E-1).fit(X_train_sel, y_train)\n",
    "    lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train,lr)\n",
    "    add_df.iloc[f_ind,:] = [X_labels[f_ind],\"x\"+str(f_ind+1),lr.score(X_train_sel, y_train),q2]\n",
    "\n",
    "if update_model and X_labelname.index(add_df['Training Q2'].idxmax()) not in features_py:\n",
    "    features_py.append(X_labelname.index(add_df['Training Q2'].idxmax()))\n",
    "add_df.sort_values(by=['Training Q2'],ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:45:06.449973Z",
     "start_time": "2021-11-03T22:45:06.405093Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove each individual feature from the manual model\n",
    "print(\"\\n\"+\" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "\n",
    "rem_df = pd.DataFrame(index=[X_labelname[i] for i in features_py],\n",
    "                      columns=[\"Training R2\",\"Training Q2\"])\n",
    "for f_ind in features_py:\n",
    "    features_iter = [i for i in features_py if i != f_ind]\n",
    "#     print(feature, x_names[f_ind])\n",
    "    X_train_sel = X_train_sc[:,features_iter]\n",
    "    X_test_sel = X_test_sc[:,features_iter]\n",
    "    # lr = Ridge(alpha=1E-1).fit(X_train_sel, y_train)\n",
    "    lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train,lr)\n",
    "    rem_df.loc[X_labelname[f_ind],:] = [lr.score(X_train_sel, y_train),q2]\n",
    "\n",
    "rem_df.sort_values(by=['Training Q2'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward stepwise selection based on p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:26:41.963967Z",
     "start_time": "2021-11-04T20:26:40.754531Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Forward stepwise selection based on p-value\n",
    "# threshold values refer to p-value of individual features\n",
    "threshold_in = 0.05\n",
    "threshold_out = 0.075 # must be larger than threshold_in\n",
    "\n",
    "use_manual_feats = False # if True, model from previous section will be used as starting point\n",
    "\n",
    "import stepwise_selection2 as step_s\n",
    "if not use_manual_feats:\n",
    "    features_py=[]\n",
    "\n",
    "features_py = step_s.stepwise_selection(pd.DataFrame(X_train_sc), y_train,\n",
    "                    initial_list=features_py,threshold_in=threshold_in,threshold_out=threshold_out,verbose=True)\n",
    "\n",
    "print(\"\\n\"+\" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "print(\"\\n\"+\" + \".join([X_labelname[i] for i in sorted(features_py)]))\n",
    "\n",
    "X_train_sel = X_train_sc[:,features_py]\n",
    "X_test_sel = X_test_sc[:,features_py]\n",
    "lr = RidgeCV(alphas=np.logspace(-6,3,10), cv=3).fit(X_train_sel, y_train) \n",
    "print(f'\\nalpha: {lr.alpha_}')\n",
    "#lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100,reg=LinearRegression())\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(features_py)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(features_py)[i]]) for i in range(len(features_py))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu)) \n",
    "    \n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"\",loo_pred=loo_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## other forward feature selection implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:19:05.633799Z",
     "start_time": "2021-11-08T21:19:05.428321Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Scikit-learn - forward feature selection\n",
    "# largely useless\n",
    "# options for criteria: \n",
    "# mutual_info_regression, f_regression\n",
    "# select number of features with k\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "criteria = f_regression\n",
    "skb = SelectKBest(criteria,k=4).fit(X_train_sc,y_train)\n",
    "selected_feats = skb.get_support(indices=True)\n",
    "print(\" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\n\"+\" + \".join([X_names[i] for i in sorted(selected_feats)]))\n",
    "\n",
    "X_train_sel = skb.transform(X_train_sc)\n",
    "X_test_sel = skb.transform(X_test_sc)\n",
    "lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n",
    "# uncomment to add model to candidate list\n",
    "# keepmodels.append(features_py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:27:56.618817Z",
     "start_time": "2021-11-04T20:27:36.467461Z"
    }
   },
   "outputs": [],
   "source": [
    "# Forward stepwise selection based on AIC (\"aic\") or Q2 (\"q2\")\n",
    "criteria = \"aic\"\n",
    "#criteria = \"q2\"\n",
    "\n",
    "import forwardselect_q5 as fsq\n",
    "\n",
    "df = pd.DataFrame(np.hstack((X_train_sc,y_train[:,None])))\n",
    "\n",
    "newcols = [\"x\"+str(i+1) for i in df.columns.values]\n",
    "df.columns = newcols\n",
    "response = newcols[-1]\n",
    "df.rename(columns={response:\"y\"},inplace=True)\n",
    "a,b = fsq.Forward_Select(df,\"y\",\"Regression\",criteria)\n",
    "selected_feats = [int(i[1:]) for i in b]\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\n\"+\" + \".join([X_names[i] for i in sorted(selected_feats)]))\n",
    "\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "lr = LinearRegression().fit(X_train_sel, y_train)\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "print(\"\\n\\n\")\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n",
    "# uncomment to add model to candidate list\n",
    "# keepmodels.append(features_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward stepwise selection keeping a set of candidates at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:29:43.957679Z",
     "start_time": "2021-11-04T20:29:23.692078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Step 2\n",
      "Finished 1 and 2 parameter models. Time taken (sec): 65.6584\n",
      "Step 3\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "Step 4\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "Step 5\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "Step 6\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "Step 7\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "Step 8\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "Step 9\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "Done. Time taken (minutes): 11.83\n",
      "\n",
      "Split method: random\n",
      "Test ratio: 0.3\n",
      "\n",
      "\n",
      "Best model:\n",
      "1 + x127 + x164 + x605 + x683 + x846 + x897 + x899 + x914 + x935\n",
      "1 + FMN_B1_31-13_MD_wt + 66_PA_max + 342_B1_2-5_min + dynam_SA_66_100_177 + 232_phi-max + NBO_alpha_C_pdt + NBO_alpha_C_pdt_max + NBO_beta_H_pdt_max + N_lg_sterimol_L_sub_min\n",
      "\n",
      "Features: x127 + x164 + x605 + x683 + x846 + x897 + x899 + x914 + x935\n",
      "\n",
      "Parameters:\n",
      "   -0.8963 + \n",
      "   -0.1859 * x127 FMN_B1_31-13_MD_wt\n",
      "    0.1523 * x164 66_PA_max\n",
      "   -0.2683 * x605 dynam_SA_66_100_177\n",
      "   -0.1047 * x683 232_phi-max\n",
      "   -0.0582 * x846 pdt_dynam_vol_total\n",
      "    0.2138 * x897 NBO_alpha_C_pdt\n",
      "   -0.1380 * x899 NBO_alpha_C_pdt_max\n",
      "   -0.2166 * x914 NBO_beta_H_pdt_max\n",
      "   -0.1705 * x935 N_lg_sterimol_L_sub_min\n",
      "\n",
      "Training R2  = 0.890\n",
      "Training Q2  = 0.827\n",
      "Training MAE = 0.136\n",
      "Training K-fold R2 = 0.804 (+/- 0.002)\n",
      "\n",
      "Test R2      = 0.159\n",
      "Test MAE     = 0.361\n",
      "\n",
      "the bad model store called. they're running out of your models\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Forward stepwise selection keeping a set of candidates at each step\n",
    "n_steps = 9 #limit to number of features we want, will find those with less\n",
    "n_candidates = 10 #smaller number of candidates speeds up code but often misses models - robust screen number of candidates = parameteres - steps\n",
    "collin_criteria = 0.5 # this is R2\n",
    "skipfeatures = [] #[\"x4\",\"x3\"]\n",
    "\n",
    "import ForwardStepCandidates_2 as fsc\n",
    "df = pd.DataFrame(np.hstack((X_train_sc,y_train[:,None])))\n",
    "newcols = [\"x\"+str(i+1) for i in df.columns.values]\n",
    "df.columns = newcols\n",
    "response = newcols[-1]\n",
    "df.rename(columns={response:\"y\"},inplace=True)\n",
    "df.drop(skipfeatures,axis=1,inplace=True)\n",
    "\n",
    "results,models,scores,sortedmodels,candidates = fsc.ForwardStep_py(df,'y',\n",
    "                    n_steps=n_steps,n_candidates=n_candidates,collin_criteria=collin_criteria)\n",
    "model_sel = results.loc[0,\"Model\"]\n",
    "selected_feats = sorted([X_labels.index(i) for i in models[model_sel].terms])\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(\"\\nBest model:\")\n",
    "print(models[model_sel].formula)\n",
    "print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[candidates[0]].terms])+\"\\n\")\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n",
      "Step 2\n",
      "Finished 1 and 2 parameter models. Time taken (sec): 66.5448\n",
      "Step 3\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "Step 4\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "cutpar:  1\n",
      "Step 5\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "Step 6\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "Step 7\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "cutpar:  2\n",
      "Step 8\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "Step 9\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "cutpar:  3\n",
      "Done. Time taken (minutes): 667.53\n"
     ]
    }
   ],
   "source": [
    "# Forward stepwise selection keeping a set of candidates at each step\n",
    "# This iteratively computes the test R^2 for model sorting\n",
    "n_steps = 9 #limit to number of features we want, will find those with less\n",
    "n_candidates = 200 #smaller number of candidates speeds up code but often misses models - robust screen number of candidates = parameteres - steps\n",
    "collin_criteria = 0.5 # this is R2\n",
    "skipfeatures = [] #[\"x4\",\"x3\"]\n",
    "\n",
    "import ForwardStepCandidates_2 as fsc\n",
    "df = pd.DataFrame(np.hstack((X_train_sc,y_train[:,None])))\n",
    "newcols = [\"x\"+str(i+1) for i in df.columns.values]\n",
    "df.columns = newcols\n",
    "response = newcols[-1]\n",
    "df.rename(columns={response:\"y\"},inplace=True)\n",
    "df.drop(skipfeatures,axis=1,inplace=True)\n",
    "\n",
    "results,models,scores,sortedmodels,candidates = fsc.ForwardStep_py(df,'y',n_steps=n_steps,n_candidates=n_candidates,collin_criteria=collin_criteria)\n",
    "\n",
    "def get_MAE(X_train_sel, y_train):\n",
    "    return lr.score(X_train_sel, y_train)\n",
    "\n",
    "def test_R2(y_train,y_pred_train):\n",
    "    return metrics.mean_absolute_error(y_train,y_pred_train)\n",
    "\n",
    "test_r2 = []\n",
    "mae = []\n",
    "\n",
    "#iterate all models and get the scores\n",
    "for index, row in results.iterrows():\n",
    "    \n",
    "    model_sel = results.loc[index,\"Model\"]\n",
    "    selected_feats = sorted([X_labels.index(i) for i in models[model_sel].terms])\n",
    "    X_train_sel = X_train_sc[:,selected_feats]\n",
    "    X_test_sel = X_test_sc[:,selected_feats]\n",
    "\n",
    "    lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "\n",
    "    y_pred_train = lr.predict(X_train_sel)\n",
    "    y_pred_test =  lr.predict(X_test_sel)\n",
    "    \n",
    "    test_r2.append(get_MAE(X_test_sel, y_test))\n",
    "    mae.append(test_R2(y_test,y_pred_test))\n",
    "\n",
    "selmods = results.sort_values(by=['Q^2'],ascending=False)\n",
    "selmods['Test_R2'] = test_r2\n",
    "selmods['MAE'] = mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View models as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:51:09.948164Z",
     "start_time": "2021-11-03T22:51:09.915280Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>n_terms</th>\n",
       "      <th>R^2</th>\n",
       "      <th>Q^2</th>\n",
       "      <th>Test_R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84188</th>\n",
       "      <td>(x527, x589, x637)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.622201</td>\n",
       "      <td>0.552483</td>\n",
       "      <td>0.783202</td>\n",
       "      <td>0.169302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70992</th>\n",
       "      <td>(x289, x316, x768, x912, x92, x934)</td>\n",
       "      <td>6</td>\n",
       "      <td>0.768930</td>\n",
       "      <td>0.666814</td>\n",
       "      <td>0.772339</td>\n",
       "      <td>0.154508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76343</th>\n",
       "      <td>(x578, x589, x614)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.676546</td>\n",
       "      <td>0.617971</td>\n",
       "      <td>0.771238</td>\n",
       "      <td>0.166714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55582</th>\n",
       "      <td>(x279, x309, x486, x586, x605, x933)</td>\n",
       "      <td>6</td>\n",
       "      <td>0.807970</td>\n",
       "      <td>0.726651</td>\n",
       "      <td>0.763501</td>\n",
       "      <td>0.164527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71469</th>\n",
       "      <td>(x425, x520, x605, x622, x837, x913, x933)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.775305</td>\n",
       "      <td>0.662339</td>\n",
       "      <td>0.761060</td>\n",
       "      <td>0.170032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71632</th>\n",
       "      <td>(x514, x578, x586, x614, x70)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.747251</td>\n",
       "      <td>0.660898</td>\n",
       "      <td>0.759285</td>\n",
       "      <td>0.165937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62064</th>\n",
       "      <td>(x160, x221, x441, x731, x768, x912, x933)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.796780</td>\n",
       "      <td>0.699213</td>\n",
       "      <td>0.755724</td>\n",
       "      <td>0.164654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81973</th>\n",
       "      <td>(x225, x513, x520, x597, x816, x835, x934)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.721059</td>\n",
       "      <td>0.575946</td>\n",
       "      <td>0.754318</td>\n",
       "      <td>0.192685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71575</th>\n",
       "      <td>(x121, x221, x605, x794, x830, x912, x933)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.770359</td>\n",
       "      <td>0.661357</td>\n",
       "      <td>0.753604</td>\n",
       "      <td>0.179914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69907</th>\n",
       "      <td>(x374, x527, x589, x637, x797)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.749748</td>\n",
       "      <td>0.675024</td>\n",
       "      <td>0.753472</td>\n",
       "      <td>0.189588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103915</th>\n",
       "      <td>(x240, x281, x514, x598, x836, x896, x933)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.602678</td>\n",
       "      <td>0.397264</td>\n",
       "      <td>0.752831</td>\n",
       "      <td>0.198610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73397</th>\n",
       "      <td>(x141, x598, x605, x681, x792, x836, x837, x933)</td>\n",
       "      <td>8</td>\n",
       "      <td>0.776856</td>\n",
       "      <td>0.643318</td>\n",
       "      <td>0.752484</td>\n",
       "      <td>0.185173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39676</th>\n",
       "      <td>(x141, x577, x598, x605, x681, x792, x836, x83...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.860282</td>\n",
       "      <td>0.771738</td>\n",
       "      <td>0.749699</td>\n",
       "      <td>0.173843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81785</th>\n",
       "      <td>(x527, x589, x637, x895)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.665059</td>\n",
       "      <td>0.577766</td>\n",
       "      <td>0.747608</td>\n",
       "      <td>0.186831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43538</th>\n",
       "      <td>(x141, x577, x598, x605, x681, x792, x837, x933)</td>\n",
       "      <td>8</td>\n",
       "      <td>0.839645</td>\n",
       "      <td>0.756784</td>\n",
       "      <td>0.745210</td>\n",
       "      <td>0.172208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81417</th>\n",
       "      <td>(x106, x249, x597, x743, x811, x836, x933)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.708831</td>\n",
       "      <td>0.582187</td>\n",
       "      <td>0.744710</td>\n",
       "      <td>0.177556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72556</th>\n",
       "      <td>(x127, x229, x54, x589, x605, x828, x944)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.757452</td>\n",
       "      <td>0.651579</td>\n",
       "      <td>0.742280</td>\n",
       "      <td>0.177431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82150</th>\n",
       "      <td>(x201, x205, x514, x597, x614, x836, x934)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.708901</td>\n",
       "      <td>0.573954</td>\n",
       "      <td>0.740424</td>\n",
       "      <td>0.185562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66806</th>\n",
       "      <td>(x374, x527, x589, x637, x797, x811)</td>\n",
       "      <td>6</td>\n",
       "      <td>0.770090</td>\n",
       "      <td>0.687135</td>\n",
       "      <td>0.739615</td>\n",
       "      <td>0.192411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72699</th>\n",
       "      <td>(x527, x589, x637, x797)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.718738</td>\n",
       "      <td>0.650028</td>\n",
       "      <td>0.739356</td>\n",
       "      <td>0.202494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80711</th>\n",
       "      <td>(x131, x490, x589, x609, x895)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.708203</td>\n",
       "      <td>0.588561</td>\n",
       "      <td>0.737365</td>\n",
       "      <td>0.180378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43804</th>\n",
       "      <td>(x577, x598, x605, x681, x792, x836, x837, x933)</td>\n",
       "      <td>8</td>\n",
       "      <td>0.843992</td>\n",
       "      <td>0.756072</td>\n",
       "      <td>0.734956</td>\n",
       "      <td>0.180273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67639</th>\n",
       "      <td>(x289, x316, x768, x846, x912, x92, x934)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.791028</td>\n",
       "      <td>0.684697</td>\n",
       "      <td>0.734795</td>\n",
       "      <td>0.176064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71106</th>\n",
       "      <td>(x225, x35, x439, x589, x642)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.744353</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.730406</td>\n",
       "      <td>0.195629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100610</th>\n",
       "      <td>(x589, x732)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.483222</td>\n",
       "      <td>0.425079</td>\n",
       "      <td>0.729911</td>\n",
       "      <td>0.182233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100505</th>\n",
       "      <td>(x589, x733)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.484465</td>\n",
       "      <td>0.425927</td>\n",
       "      <td>0.729447</td>\n",
       "      <td>0.182052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80640</th>\n",
       "      <td>(x201, x205, x514, x597, x614, x836)</td>\n",
       "      <td>6</td>\n",
       "      <td>0.704172</td>\n",
       "      <td>0.589154</td>\n",
       "      <td>0.729383</td>\n",
       "      <td>0.182855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76054</th>\n",
       "      <td>(x490, x589, x609, x895)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.696072</td>\n",
       "      <td>0.620381</td>\n",
       "      <td>0.729225</td>\n",
       "      <td>0.191091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62056</th>\n",
       "      <td>(x153, x598, x733, x797, x836, x846)</td>\n",
       "      <td>6</td>\n",
       "      <td>0.787282</td>\n",
       "      <td>0.699234</td>\n",
       "      <td>0.728636</td>\n",
       "      <td>0.186875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64930</th>\n",
       "      <td>(x222, x287, x567, x796, x837, x913, x934)</td>\n",
       "      <td>7</td>\n",
       "      <td>0.806951</td>\n",
       "      <td>0.691458</td>\n",
       "      <td>0.728183</td>\n",
       "      <td>0.185655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Model  n_terms       R^2  \\\n",
       "84188                                  (x527, x589, x637)        3  0.622201   \n",
       "70992                 (x289, x316, x768, x912, x92, x934)        6  0.768930   \n",
       "76343                                  (x578, x589, x614)        3  0.676546   \n",
       "55582                (x279, x309, x486, x586, x605, x933)        6  0.807970   \n",
       "71469          (x425, x520, x605, x622, x837, x913, x933)        7  0.775305   \n",
       "71632                       (x514, x578, x586, x614, x70)        5  0.747251   \n",
       "62064          (x160, x221, x441, x731, x768, x912, x933)        7  0.796780   \n",
       "81973          (x225, x513, x520, x597, x816, x835, x934)        7  0.721059   \n",
       "71575          (x121, x221, x605, x794, x830, x912, x933)        7  0.770359   \n",
       "69907                      (x374, x527, x589, x637, x797)        5  0.749748   \n",
       "103915         (x240, x281, x514, x598, x836, x896, x933)        7  0.602678   \n",
       "73397    (x141, x598, x605, x681, x792, x836, x837, x933)        8  0.776856   \n",
       "39676   (x141, x577, x598, x605, x681, x792, x836, x83...        9  0.860282   \n",
       "81785                            (x527, x589, x637, x895)        4  0.665059   \n",
       "43538    (x141, x577, x598, x605, x681, x792, x837, x933)        8  0.839645   \n",
       "81417          (x106, x249, x597, x743, x811, x836, x933)        7  0.708831   \n",
       "72556           (x127, x229, x54, x589, x605, x828, x944)        7  0.757452   \n",
       "82150          (x201, x205, x514, x597, x614, x836, x934)        7  0.708901   \n",
       "66806                (x374, x527, x589, x637, x797, x811)        6  0.770090   \n",
       "72699                            (x527, x589, x637, x797)        4  0.718738   \n",
       "80711                      (x131, x490, x589, x609, x895)        5  0.708203   \n",
       "43804    (x577, x598, x605, x681, x792, x836, x837, x933)        8  0.843992   \n",
       "67639           (x289, x316, x768, x846, x912, x92, x934)        7  0.791028   \n",
       "71106                       (x225, x35, x439, x589, x642)        5  0.744353   \n",
       "100610                                       (x589, x732)        2  0.483222   \n",
       "100505                                       (x589, x733)        2  0.484465   \n",
       "80640                (x201, x205, x514, x597, x614, x836)        6  0.704172   \n",
       "76054                            (x490, x589, x609, x895)        4  0.696072   \n",
       "62056                (x153, x598, x733, x797, x836, x846)        6  0.787282   \n",
       "64930          (x222, x287, x567, x796, x837, x913, x934)        7  0.806951   \n",
       "\n",
       "             Q^2   Test_R2       MAE  \n",
       "84188   0.552483  0.783202  0.169302  \n",
       "70992   0.666814  0.772339  0.154508  \n",
       "76343   0.617971  0.771238  0.166714  \n",
       "55582   0.726651  0.763501  0.164527  \n",
       "71469   0.662339  0.761060  0.170032  \n",
       "71632   0.660898  0.759285  0.165937  \n",
       "62064   0.699213  0.755724  0.164654  \n",
       "81973   0.575946  0.754318  0.192685  \n",
       "71575   0.661357  0.753604  0.179914  \n",
       "69907   0.675024  0.753472  0.189588  \n",
       "103915  0.397264  0.752831  0.198610  \n",
       "73397   0.643318  0.752484  0.185173  \n",
       "39676   0.771738  0.749699  0.173843  \n",
       "81785   0.577766  0.747608  0.186831  \n",
       "43538   0.756784  0.745210  0.172208  \n",
       "81417   0.582187  0.744710  0.177556  \n",
       "72556   0.651579  0.742280  0.177431  \n",
       "82150   0.573954  0.740424  0.185562  \n",
       "66806   0.687135  0.739615  0.192411  \n",
       "72699   0.650028  0.739356  0.202494  \n",
       "80711   0.588561  0.737365  0.180378  \n",
       "43804   0.756072  0.734956  0.180273  \n",
       "67639   0.684697  0.734795  0.176064  \n",
       "71106   0.665746  0.730406  0.195629  \n",
       "100610  0.425079  0.729911  0.182233  \n",
       "100505  0.425927  0.729447  0.182052  \n",
       "80640   0.589154  0.729383  0.182855  \n",
       "76054   0.620381  0.729225  0.191091  \n",
       "62056   0.699234  0.728636  0.186875  \n",
       "64930   0.691458  0.728183  0.185655  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view best model\n",
    "selmods.sort_values(by=['Test_R2'],ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:51:14.905446Z",
     "start_time": "2021-11-03T22:51:14.869514Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>n_terms</th>\n",
       "      <th>R^2</th>\n",
       "      <th>Q^2</th>\n",
       "      <th>Test_R2</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34339</th>\n",
       "      <td>(x112, x605, x768, x910, x912)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.789972</td>\n",
       "      <td>0.716891</td>\n",
       "      <td>0.745342</td>\n",
       "      <td>0.208886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34599</th>\n",
       "      <td>(x112, x605, x768, x910, x913)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.789103</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.745290</td>\n",
       "      <td>0.206834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34302</th>\n",
       "      <td>(x112, x605, x768, x908, x913)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.789282</td>\n",
       "      <td>0.717129</td>\n",
       "      <td>0.744206</td>\n",
       "      <td>0.208194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33979</th>\n",
       "      <td>(x112, x605, x768, x908, x912)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.790205</td>\n",
       "      <td>0.719054</td>\n",
       "      <td>0.739667</td>\n",
       "      <td>0.210355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34185</th>\n",
       "      <td>(x112, x605, x768, x907, x913)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.717840</td>\n",
       "      <td>0.734756</td>\n",
       "      <td>0.212040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Model  n_terms       R^2       Q^2   Test_R2  \\\n",
       "34339  (x112, x605, x768, x910, x912)        5  0.789972  0.716891  0.745342   \n",
       "34599  (x112, x605, x768, x910, x913)        5  0.789103  0.715000  0.745290   \n",
       "34302  (x112, x605, x768, x908, x913)        5  0.789282  0.717129  0.744206   \n",
       "33979  (x112, x605, x768, x908, x912)        5  0.790205  0.719054  0.739667   \n",
       "34185  (x112, x605, x768, x907, x913)        5  0.789580  0.717840  0.734756   \n",
       "\n",
       "            MAE  \n",
       "34339  0.208886  \n",
       "34599  0.206834  \n",
       "34302  0.208194  \n",
       "33979  0.210355  \n",
       "34185  0.212040  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Change this to update sorting criteria ###\n",
    "selmods2 = selmods[selmods.n_terms <=6].sort_values(by=['Test_R2'],ascending=False)\n",
    "selmods2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:52:07.079113Z",
     "start_time": "2021-11-03T22:52:07.049200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# example for filtering results\n",
    "#filter to find models containing specified parameters\n",
    "\n",
    "l1 = [(80, 276, 589)] \n",
    "l2 = []\n",
    "for i,j,k in l1:\n",
    "    a = \"x{}\".format(i) and \"x{}\".format(j) and \"x{}\".format(k)\n",
    "    l2.append(a)\n",
    "\n",
    "selmods2 = results.loc[[i for i in results.index if any(x in l2 for x in results.loc[i,'Model']) and \"x200\" not in results.loc[i,\"Model\"]]].sort_values(by=['Q^2'],ascending=False)\n",
    "selmods2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-03T22:52:54.652810Z",
     "start_time": "2021-11-03T22:52:54.628842Z"
    }
   },
   "outputs": [],
   "source": [
    "# example for filtering results\n",
    "\n",
    "selmods2 = results.loc[[i for i in results.index if \"x113\" in results.loc[i,\"Model\"] and \"x49\" not in results.loc[i,\"Model\"]]][results.n_terms < 5].sort_values(by=['Q^2'],ascending=False)\n",
    "selmods2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-15T06:41:09.900600Z",
     "start_time": "2019-07-15T06:41:09.840203Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter models that contain more than one term that is also in a reference model\n",
    "reference_model = 0 # this number refer to the index in 'results' or 'selmods', whichever is used \n",
    "use_df = results # or: selmods\n",
    "\n",
    "uniquemods = {use_df.loc[reference_model,\"Model\"]:reference_model}\n",
    "for ind in use_df.index:\n",
    "    selmod = use_df.loc[ind,\"Model\"]\n",
    "    if len(selmod) <= 2:\n",
    "        continue\n",
    "        \n",
    "    add = True\n",
    "    for mod in uniquemods.keys():\n",
    "        if len([i for i in mod if i in selmod]) >= 2:\n",
    "            add = False\n",
    "            break\n",
    "    if add:      \n",
    "        uniquemods[use_df.loc[ind,\"Model\"]] = ind\n",
    "    \n",
    "    \n",
    "print(len(uniquemods.keys()))\n",
    "selmods2 = results.loc[uniquemods.values()]\n",
    "selmods2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:30:19.662074Z",
     "start_time": "2021-11-04T20:30:19.275110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split method: random\n",
      "Test ratio: 0.3\n",
      "\n",
      "1 + x289 + x316 + x768 + x912 + x92 + x934\n",
      "1 + 175_angle_4_min + 175_B5_5-6_max + 177_rmsd-b_min + NBO_beta_H_pdt + dynam_vol_66 + N_lg_sterimol_L_sub_max\n",
      "\n",
      "Features: x92 + x289 + x316 + x768 + x912 + x934\n",
      "\n",
      "Parameters:\n",
      "   -0.8963 + \n",
      "   -0.2943 * x92 dynam_vol_66\n",
      "    0.0356 * x289 175_angle_4_min\n",
      "   -0.1346 * x316 175_B5_5-6_max\n",
      "   -0.1472 * x768 177_rmsd-b_min\n",
      "   -0.2792 * x912 NBO_beta_H_pdt\n",
      "   -0.0850 * x934 N_lg_sterimol_L_sub_max\n",
      "\n",
      "Training R2  = 0.769\n",
      "Training Q2  = 0.667\n",
      "Training MAE = 0.199\n",
      "Training K-fold R2 = 0.648 (+/- 0.002)\n",
      "\n",
      "Test R2      = 0.772\n",
      "Test MAE     = 0.155\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.769\n",
      "Model:                            OLS   Adj. R-squared:                  0.732\n",
      "Method:                 Least Squares   F-statistic:                     21.08\n",
      "Date:                Wed, 03 Aug 2022   Prob (F-statistic):           1.04e-10\n",
      "Time:                        08:16:05   Log-Likelihood:                -1.3302\n",
      "No. Observations:                  45   AIC:                             16.66\n",
      "Df Residuals:                      38   BIC:                             29.31\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.8963      0.040    -22.169      0.000      -0.978      -0.814\n",
      "0             -0.2943      0.044     -6.670      0.000      -0.384      -0.205\n",
      "1              0.0356      0.049      0.725      0.473      -0.064       0.135\n",
      "2             -0.1346      0.051     -2.618      0.013      -0.239      -0.031\n",
      "3             -0.1472      0.044     -3.331      0.002      -0.237      -0.058\n",
      "4             -0.2792      0.042     -6.635      0.000      -0.364      -0.194\n",
      "5             -0.0850      0.046     -1.858      0.071      -0.178       0.008\n",
      "==============================================================================\n",
      "Omnibus:                        0.781   Durbin-Watson:                   1.749\n",
      "Prob(Omnibus):                  0.677   Jarque-Bera (JB):                0.523\n",
      "Skew:                          -0.263   Prob(JB):                        0.770\n",
      "Kurtosis:                       2.958   Cond. No.                         2.23\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# visualize other models\n",
    "model_sel = results.loc[70992,\"Model\"]\n",
    "\n",
    "#models we like 11308\n",
    "\n",
    "#other ways of selecting models:\n",
    "# model_sel = results.iloc[selmods.index[3],0]\n",
    "# model_sel = results.iloc[785,0]\n",
    "# model_sel = (\"x100\",\"x31\")\n",
    "\n",
    "\n",
    "selected_feats = sorted([X_labels.index(i) for i in models[model_sel].terms])\n",
    "X_train_sel = X_train_sc[:,selected_feats]\n",
    "X_test_sel = X_test_sc[:,selected_feats]\n",
    "\n",
    "print(\"Split method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "print(models[model_sel].formula)\n",
    "print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[model_sel].terms])+\"\\n\")\n",
    "lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "y_pred_train = lr.predict(X_train_sel)\n",
    "y_pred_test =  lr.predict(X_test_sel)\n",
    "\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "\n",
    "print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "\n",
    "print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "\n",
    "\n",
    "testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "trainr2 = lr.score(X_train_sel, y_train)\n",
    "if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "    print(\"\\n\"+random.choice(insu))\n",
    "    \n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)\n",
    "model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T21:21:57.116397Z",
     "start_time": "2021-11-08T21:20:17.187724Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print all models that are within a specified criteria (if statement below)\n",
    "# results.index will look at all models, selmods.index will look at filtered models\n",
    "\n",
    "#for i in results.index:\n",
    "for i in selmods.index:\n",
    "    model_sel = results.loc[i,\"Model\"]\n",
    "    \n",
    "    #other ways of selecting models:\n",
    "    # model_sel = results.iloc[selmods.index[3],0]\n",
    "    # model_sel = results.iloc[785,0]\n",
    "    # model_sel = (\"x100\",\"x31\")\n",
    "    \n",
    "    \n",
    "    selected_feats = sorted([X_labels.index(i) for i in models[model_sel].terms])\n",
    "    X_train_sel = X_train_sc[:,selected_feats]\n",
    "    X_test_sel = X_test_sc[:,selected_feats]\n",
    "    print(models[model_sel].formula)\n",
    "    print(\"1 + \"+\" + \".join([X_names[X_labels.index(i)] for i in models[model_sel].terms])+\"\\n\")\n",
    "    lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "    y_pred_train = lr.predict(X_train_sel)\n",
    "    y_pred_test =  lr.predict(X_test_sel)\n",
    "    \n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train)\n",
    "    kfoldscores_self = repeated_k_fold(X_train_sel,y_train,k=5,n=100)\n",
    "    \n",
    "    testr2 =  np.round(r2_val(y_test,y_pred_test,y_train),4)\n",
    "    trainr2 = lr.score(X_train_sel, y_train)\n",
    "    \n",
    "    #set criteria here \n",
    "    if testr2 >= 0.65 and q2>=0.6:\n",
    "        print(\"\\nSplit method: {}\".format(split))\n",
    "        print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "        \n",
    "        print(\"Features: \" + \" + \".join([\"x\"+str(i+1) for i in sorted(selected_feats)]))\n",
    "        print(\"\\nParameters:\\n{:10.4f} + \\n\".format(lr.intercept_) + \"\\n\".join([\"{:10.4f} * {}\".format(lr.coef_[i],X_labelname[sorted(selected_feats)[i]]) for i in range(len(selected_feats))]))\n",
    "        \n",
    "        print(f\"\\nTraining R2  = {lr.score(X_train_sel, y_train):.3f}\\nTraining Q2  = {q2:.3f}\")\n",
    "        print(f\"Training MAE = {metrics.mean_absolute_error(y_train,y_pred_train):.3f}\")\n",
    "        \n",
    "        print(\"Training K-fold R2 = {:.3f} (+/- {:.3f})\".format(kfoldscores_self.mean(), kfoldscores_self.std() ** 2))\n",
    "        print(f\"\\nTest R2      = {r2_val(y_test,y_pred_test,y_train):.3f}\\nTest MAE     = {metrics.mean_absolute_error(y_test,y_pred_test):.3f}\")\n",
    "    \n",
    "        if trainr2 - testr2 > 0.35 or trainr2<0.4 or testr2<0.2 or q2<0:\n",
    "            print(\"\\n\"+random.choice(insu))\n",
    "        \n",
    "        plot_fit(y_train,y_pred_train,y_test,y_pred_test,leg=False,sav=False,label=\"y\",loo_pred=loo_train)\n",
    "    \n",
    "        #model = sm.OLS(y_train, sm.add_constant(pd.DataFrame(X_train_sel))).fit()\n",
    "        #print(model.summary())\n",
    "        \n",
    "    print(\"____________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression, no feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:32:24.304743Z",
     "start_time": "2021-11-04T20:32:23.943498Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "linm = Ridge().fit(X_train_sc, y_train)\n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "parm_range = np.logspace(-4,4,9)\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    linm = Ridge(alpha=parm).fit(X_train_sc, y_train)\n",
    "    q2,loo_train = loo.q2(X_train_sc,y_train,Ridge(alpha=parm))\n",
    "    \n",
    "    y_pred_train = linm.predict(X_train_sc)\n",
    "    y_pred_test =  linm.predict(X_test_sc)\n",
    "    #print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,metrics.r2_score(y_pred_test,y_test)))\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(linm.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "    #print(lr.score(X_train_sel,y_train),lr.score(X_test_sel,y_test))\n",
    "        \n",
    "    r2s.append(linm.score(X_train_sc, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "\n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "linm = Ridge(alpha=bestparm).fit(X_train_sc, y_train)\n",
    "y_pred_train = linm.predict(X_train_sc)\n",
    "y_pred_test =  linm.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:32:43.649061Z",
     "start_time": "2021-11-04T20:32:42.905974Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Lasso feature selection\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "parm_range = np.logspace(-4,1,6)\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    lasso = Lasso(alpha=parm).fit(X_train_sc, y_train)\n",
    "    X_train_sel = X_train_sc[:,np.where(lasso.coef_!=0)[0]]\n",
    "    X_test_sel = X_test_sc[:,np.where(lasso.coef_!=0)[0]]\n",
    "    try:\n",
    "        q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "        lr = LinearRegression().fit(X_train_sel,y_train)\n",
    "        y_pred_train = lr.predict(X_train_sel)\n",
    "        y_pred_test =  lr.predict(X_test_sel)\n",
    "        #print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,metrics.r2_score(y_pred_test,y_test)))\n",
    "        print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lr.score(X_train_sel, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "        #print(lr.score(X_train_sel,y_train),lr.score(X_test_sel,y_test))\n",
    "    except:\n",
    "        pass\n",
    "    print(\"     Number of features used: {}\".format(np.sum(lasso.coef_ != 0)))\n",
    "    # print(np.where(lr.coef_ != 0)[1])\n",
    "    \n",
    "    r2s.append(lasso.score(X_train, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "\n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "lasso = Lasso(alpha=bestparm).fit(X_train_sc, y_train)\n",
    "y_pred_train = lasso.predict(X_train_sc)\n",
    "y_pred_test =  lasso.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)    \n",
    "    \n",
    "# llbic = LassoLarsIC(criterion=\"bic\").fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(llbic.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(llbic.coef_!=0)[0]]\n",
    "# print(\"\\n\\nLassoLarsIC bic\")\n",
    "# try:\n",
    "#     q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "#     print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(llbic.score(X_train_sc, y_train),q2,llbic.score(X_test_sc, y_test)))\n",
    "# except:\n",
    "#     pass\n",
    "# print(\"Number of features used: {}\".format(np.sum(llbic.coef_ != 0)))\n",
    "\n",
    "# llaic = LassoLarsIC(criterion=\"aic\").fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(llaic.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(llaic.coef_!=0)[0]]\n",
    "# print(\"\\n\\nLassoLarsIC aic\")\n",
    "# try:\n",
    "#     q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "#     print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(llaic.score(X_train_sc, y_train),q2,llaic.score(X_test_sc, y_test)))\n",
    "# except:\n",
    "#     pass\n",
    "# print(\"Number of features used: {}\".format(np.sum(llaic.coef_ != 0)))\n",
    "\n",
    "# lassocv = LassoCV(cv=LeaveOneOut()).fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(lassocv.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(lassocv.coef_!=0)[0]]\n",
    "# q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "# print(\"\\n\\nLassoCV\")\n",
    "# print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(lassocv.score(X_train_sc, y_train),q2,lassocv.score(X_test_sc, y_test)))\n",
    "# print(\"Number of features used: {}\".format(np.sum(lassocv.coef_ != 0)))\n",
    "# print(np.where(lassocv.coef_ != 0)[1])\n",
    "\n",
    "llcv = LassoLarsCV(cv=LeaveOneOut()).fit(X_train_sc, y_train)\n",
    "X_train_sel = X_train_sc[:,np.where(llcv.coef_!=0)[0]]\n",
    "X_test_sel = X_test_sc[:,np.where(llcv.coef_!=0)[0]]\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "print(\"\\n\\nLassoLarsCV\")\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(llcv.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "print(\"Number of features used: {}\".format(np.sum(llcv.coef_ != 0)))\n",
    "# print(np.where(llcv.coef_ != 0)[1])\n",
    "y_pred_train = llcv.predict(X_train_sc)\n",
    "y_pred_test =  llcv.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:01.630278Z",
     "start_time": "2021-11-04T20:33:00.977701Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "encv = ElasticNetCV(l1_ratio=[.01,.05,.66,.1,.2,.3, .5, .7, .9, .95, .99, 1],\n",
    "#                     n_alphas=500,\n",
    "                    alphas=np.logspace(-1,4,100),\n",
    "                    cv=3,n_jobs=-1,max_iter=1000000).fit(X_train_sc, y_train)\n",
    "X_train_sel = X_train_sc[:,np.where(encv.coef_!=0)[0]]\n",
    "X_test_sel = X_test_sc[:,np.where(encv.coef_!=0)[0]]\n",
    "q2,loo_train = loo.q2(X_train_sel,y_train,Ridge(alpha=encv.alpha_))\n",
    "y_pred_train = encv.predict(X_train_sc)\n",
    "y_pred_test =  encv.predict(X_test_sc)\n",
    "print(\"\\n\\nElasticNetCV\")\n",
    "print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(encv.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "print(\"Number of features used: {}\".format(np.sum(encv.coef_ != 0)))\n",
    "print(\"Best hyperparameters: l1_ratio = {}, alpha = {}\".format(encv.l1_ratio_,encv.alpha_))\n",
    "\n",
    "\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonal Matching Pursuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:12.560161Z",
     "start_time": "2021-11-04T20:33:12.448401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Orthogonal Matching Pursuit\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "parm_range = range(1,10)\n",
    "print(np.shape(X_train_sc))\n",
    "print(np.shape(y_train))\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    omp = OrthogonalMatchingPursuit(n_nonzero_coefs=parm).fit(X_train_sc, y_train)\n",
    "    X_train_sel = X_train_sc[:,np.where(omp.coef_!=0)[0]]\n",
    "    X_test_sel = X_test_sc[:,np.where(omp.coef_!=0)[0]]\n",
    "    q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "    y_pred_train = omp.predict(X_train_sc)\n",
    "    y_pred_test =  omp.predict(X_test_sc)\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(omp.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "    print(\"     \"+\" + \".join([\"x\"+str(i+1) for i in np.where(omp.coef_ != 0)[0]]))\n",
    "    #print(\"     Number of features used: {}\".format(np.sum(lr.coef_ != 0)))\n",
    "    \n",
    "\n",
    "# ompcv = OrthogonalMatchingPursuitCV(cv=LeaveOneOut(),n_jobs=-1).fit(X_train_sc, y_train)\n",
    "# X_train_sel = X_train_sc[:,np.where(ompcv.coef_!=0)[0]]\n",
    "# X_test_sel = X_test_sc[:,np.where(ompcv.coef_!=0)[0]]\n",
    "# q2,loo_train = loo.q2(X_train_sel,y_train,LinearRegression())\n",
    "# print(\"\\n\\nOrthogonalMatchingPursuitCV\")\n",
    "# print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(ompcv.score(X_train_sc, y_train),q2,ompcv.score(X_test_sc, y_test)))\n",
    "# print(\"Number of features used: {}\".format(np.sum(ompcv.coef_ != 0)))\n",
    "\n",
    "# print(\"\\n\"+\" + \".join([\"x\"+str(i+1) for i in np.where(ompcv.coef_!=0)[0]]))\n",
    "# print(\"\\n\"+\" + \".join([X_names[i] for i in np.where(ompcv.coef_!=0)[0]]))\n",
    "\n",
    "# y_pred_train = ompcv.predict(X_train_sc)\n",
    "# y_pred_test =  ompcv.predict(X_test_sc)\n",
    "# plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:17.815213Z",
     "start_time": "2021-11-04T20:33:17.481107Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Kernel Ridge Regression \n",
    "# kernel options: linear, poly, rbf\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio)) \n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "print(\"\\n\\nKernelRidge\")\n",
    "\n",
    "kernel=\"poly\" #rbf (only works if properties are related)\n",
    "degree=2  #2 simulates crossterms \n",
    "\n",
    "parm_range = np.logspace(-3,3,7)\n",
    "for parm in parm_range:\n",
    "    print(parm)\n",
    "    kr = KernelRidge(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        alpha=parm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "    y_pred_train = kr.predict(X_train_sc)\n",
    "    y_pred_test =  kr.predict(X_test_sc)\n",
    "    q2,loo_train = loo.q2(X_train_sc,y_train,KernelRidge(kernel=kernel,degree=degree,alpha=parm))\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(\n",
    "        kr.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "    r2s.append(kr.score(X_train, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "    \n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "kr = KernelRidge(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        alpha=bestparm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "y_pred_train = kr.predict(X_train_sc)\n",
    "y_pred_test =  kr.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:33:23.350395Z",
     "start_time": "2021-11-04T20:33:22.952944Z"
    }
   },
   "outputs": [],
   "source": [
    "# SVR\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "\n",
    "r2s = []\n",
    "q2s = []\n",
    "parms = []\n",
    "print(\"\\n\\nSupport Vector Regression\")\n",
    "\n",
    "kernel=\"poly\"\n",
    "degree=2\n",
    "gamma=\"auto\"\n",
    "\n",
    "parm_range = np.logspace(-3,3,15)\n",
    "for parm in parm_range:\n",
    "    print(\"{:.2E}\".format(parm))\n",
    "    svr = SVR(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        gamma=gamma,\n",
    "        C=parm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "    y_pred_train = svr.predict(X_train_sc)\n",
    "    y_pred_test =  svr.predict(X_test_sc)\n",
    "    q2,loo_train = loo.q2(X_train_sc,y_train,SVR(kernel=kernel,degree=degree,gamma=gamma,C=parm))\n",
    "    print(\"     Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(\n",
    "        svr.score(X_train_sc, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "    r2s.append(svr.score(X_train, y_train))\n",
    "    q2s.append(q2)\n",
    "    parms.append(parm)\n",
    "    \n",
    "bestparm = parms[np.argmax(q2s)]\n",
    "print(\"\\n\\nUsing hyperparameter = {}\".format(bestparm))\n",
    "svr = SVR(\n",
    "        kernel=kernel,\n",
    "        degree=degree,\n",
    "        gamma=gamma,\n",
    "        C=bestparm\n",
    "    ).fit(X_train_sc, y_train)\n",
    "y_pred_train = svr.predict(X_train_sc)\n",
    "y_pred_test =  svr.predict(X_test_sc)\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "   \n",
    "\n",
    "# keepmodels_[svr] = ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:34:05.479348Z",
     "start_time": "2021-11-04T20:34:03.666109Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Regression with Principal Components\n",
    "\n",
    "for npca in range(1,9):\n",
    "    pca = PCA(n_components=npca)\n",
    "    pca.fit(scaler.transform(X_sel))\n",
    "#     pca.fit(X_train_sc)\n",
    "    X_train_pca = pca.transform(X_train_sc)\n",
    "    X_test_pca = pca.transform(X_test_sc)\n",
    "\n",
    "    pca_score = pca.explained_variance_ratio_\n",
    "    pca_values = pca.singular_values_\n",
    "    V = pca.components_\n",
    "\n",
    "    linr = LinearRegression().fit(X_train_pca, y_train)\n",
    "#     linr = Ridge(alpha=1).fit(X_train_pca,y_train)\n",
    "    y_pred_train = linr.predict(X_train_pca)\n",
    "    y_pred_test =  linr.predict(X_test_pca)\n",
    "    q2,loo_train = loo.q2(X_train_pca,y_train,LinearRegression())\n",
    "    print(\"\\nSplit method: {}\".format(split))\n",
    "    print(\"Test ratio: {}\".format(test_ratio))\n",
    "    print(\"\\nPC Regression {}\".format(npca))\n",
    "    print(\"Training R2;Training Q2;Test R2;{:.2f};{:.2f};{:.2f}\".format(\n",
    "        linr.score(X_train_pca, y_train),q2,r2_val(y_test,y_pred_test,y_train)))\n",
    "\n",
    "\n",
    "\n",
    "    plot_fit(y_train,y_pred_train,y_test,y_pred_test)\n",
    "\n",
    "    \n",
    "# # virtual screening\n",
    "# X_screen_sel = pca.transform(X_all_sc)\n",
    "# y_pred_vscreen = linr.predict(X_screen_sel)\n",
    "# y_vscreen[\"PCA5\"] = y_pred_vscreen\n",
    "\n",
    "\n",
    "# keepmodels_[PCA(n_components=2).fit(scaler.transform(X_sel))] = (\"n_components=2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-04T20:34:18.872212Z",
     "start_time": "2021-11-04T20:34:18.001568Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random forest regression\n",
    "\n",
    "rf  = RandomForestRegressor(n_estimators=500,random_state=42,n_jobs=None,max_features=None,max_depth=None).fit(\n",
    "    X_train_sc, y_train)\n",
    "# rf = GradientBoostingRegressor(\n",
    "#     n_estimators=50,\n",
    "#     subsample=.6,\n",
    "#     max_depth=2,\n",
    "#     random_state=42,\n",
    "#     max_features=None,\n",
    "#     alpha=0.9,\n",
    "#     ).fit(X_train_sc, y_train)\n",
    "y_pred_train = rf.predict(X_train_sc)\n",
    "y_pred_test =  rf.predict(X_test_sc)\n",
    "print(\"\\nSplit method: {}\".format(split))\n",
    "print(\"Test ratio: {}\\n\".format(test_ratio))\n",
    "print(\"Training R2;Test R2;{:.2f};{:.2f}\".format(\n",
    "    rf.score(X_train_sc, y_train),r2_val(y_test,y_pred_test,y_train)))\n",
    "# print(np.where(llcv.coef_ != 0)[1])\n",
    "\n",
    "plot_fit(y_train,y_pred_train,y_test,y_pred_test)   \n",
    "\n",
    "# keepmodels_[rf] = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "314px",
    "width": "313px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "325.016px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": "400"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 959.666666,
   "position": {
    "height": "981.263px",
    "left": "1534.33px",
    "right": "20px",
    "top": "5px",
    "width": "631.037px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
